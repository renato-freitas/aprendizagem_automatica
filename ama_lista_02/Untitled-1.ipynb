{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "num_pos = 5000\n",
    "alfa = 0.0001\n",
    "epocas = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bivariate normal distribution mean [0, 0] [0.5, 4], with a covariance matrix\n",
    "subset1 = np.random.multivariate_normal([0, 0], [[1, 0.6],[0.6, 1]], num_pos)\n",
    "subset2 = np.random.multivariate_normal([0.5, 4], [[1, 0.6],[0.6, 1]], num_pos)\n",
    "subset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.vstack((subset1, subset2))\n",
    "x = np.hstack((np.ones(num_pos*2).reshape(num_pos*2, 1), dataset)) # add 1 for beta_0 intercept\n",
    "label = np.hstack((np.zeros(num_pos), np.ones(num_pos)))\n",
    "y = label.reshape(num_pos*2, 1) # reshape y to make 2D shape (n, 1)\n",
    "beta = np.zeros(x.shape[1]).reshape(x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After step 1, likelihood: [[-6931.4718056]]; accuracy: 0.5\n",
      "After step 5001, likelihood: [[-271.79049203]]; accuracy: 0.9907\n",
      "After step 10001, likelihood: [[-270.9362711]]; accuracy: 0.9906\n",
      "After step 15001, likelihood: [[-270.89686405]]; accuracy: 0.9907\n",
      "After step 20001, likelihood: [[-270.8941212]]; accuracy: 0.9907\n",
      "After step 25001, likelihood: [[-270.89397015]]; accuracy: 0.9907\n",
      "After step 30001, likelihood: [[-270.89410983]]; accuracy: 0.9907\n",
      "After step 35001, likelihood: [[-270.89481279]]; accuracy: 0.9907\n",
      "After step 40001, likelihood: [[-270.89454763]]; accuracy: 0.9907\n",
      "After step 45001, likelihood: [[-270.89452181]]; accuracy: 0.9907\n",
      "[[-10.64893286]\n",
      " [ -3.02754819]\n",
      " [  5.7330839 ]]\n"
     ]
    }
   ],
   "source": [
    "for step in np.arange(epocas):\n",
    "    x_beta = np.dot(x, beta)\n",
    "    y_hat = 1 / (1 + np.exp(-x_beta))\n",
    "    likelihood = np.sum(np.log(1 - y_hat)) + np.dot(y.T, x_beta)\n",
    "    preds = np.round( y_hat )\n",
    "    accuracy = np.sum(preds == y)*1.00/len(preds)\n",
    "    gradient = np.dot(np.transpose(x), y - y_hat)\n",
    "    beta = beta + alfa*gradient\n",
    "    if( step % 5000 == 0):\n",
    "        print(\"After step {}, likelihood: {}; accuracy: {}\".format(step+1, likelihood, accuracy))\n",
    "    \n",
    "\n",
    "print(beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DICAS QUESTÃO 2\n",
    "avaliação cruzada 10 folds\n",
    "[][][][][][][][][]|[teste]\n",
    "no final tem-se 10 acurácias\n",
    "soma das acuários/10\n",
    "\n",
    "serão 10 modelos\n",
    "\n",
    "\n",
    "RL\n",
    "altera a dimensao dos paremateso\n",
    "alterar a função custo\n",
    "\n",
    "\n",
    "função custo RL = cross entropy BINÁRIA\n",
    " RMulti = cross entropy multi\n",
    "\n",
    "\n",
    " sujeiro no log 10e-15\n",
    "\n",
    "\n",
    " dica2 \n",
    " usar a versão matricial\n",
    "\n",
    "\n",
    " Y = [\n",
    "  [1 0 0 ]\n",
    "  [0 1 0 ]\n",
    " ]\n",
    "\n",
    "\n",
    "pode usar o kfold\n",
    "pode usar o oneHotEncoding\n",
    "\n",
    " ---------------\n",
    " DISCRI GAUSSIANO TENHO 4 VETORES MEDIAS (K) DIMENSÃO 30X1\n",
    " 4 MATRIZ DE COVARIANCIA 30X30\n",
    " ----------------\n",
    " NAIVE BAYES:\n",
    " - mDK É 1X1\n",
    " - GDK É 1X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (266912488.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [2]\u001b[1;36m\u001b[0m\n\u001b[1;33m    cv = KFold(n_splits=10, random_state=1, shuffle=True)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Realizando o processo de one-hot encoding do tipo primário do pokemon\n",
    "con = pd.Series(list('abcba'))\n",
    "print(con)\n",
    "print(pd.get_dummies(con))\n",
    "\n",
    "def cross_validation(modelo, X, Y, k):\n",
    "  # https://www.section.io/engineering-education/how-to-implement-k-fold-cross-validation/\n",
    "  # https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/\n",
    "  # https://medium.com/@edubrazrabello/cross-validation-avaliando-seu-modelo-de-machine-learning-1fb70df15b78\n",
    "\n",
    "  # https://sites.google.com/site/ufcregis/home/2018-1/aprendizado-de-maquina\n",
    "  # https://learn.theprogrammingfoundation.org/getting_started/intro_data_science/module4/?gclid=CjwKCAjw__ihBhADEiwAXEazJmKuGUWfIX6zsH49kW6YxqNJxY3HBFli0TB3ssd5Ukj5Bw72JK8eXRoC0jEQAvD_BwE\n",
    "#https://github.com/viniciuslazzari/PokemonPrediction/blob/main/main.py\n",
    "# [1,x1,x2, x1_2, x2_2, x1_3,x2_3]\n",
    "\n",
    "# https://github.com/regispires/aulas-machine-learning/blob/master/08-Logistic%20Regression%202.ipynb\n",
    "\n",
    "# https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Gaussian%20Naive%20Bayes.ipynb\n",
    "\n",
    "\n",
    "  # https://medium.com/mlearning-ai/multiclass-logistic-regression-with-python-2ee861d5772a\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise do Discriminante Gaussiano\n",
    "\n",
    "$p(c_k) = N_k/N$\n",
    "\n",
    "$P(x|C_1) = N(u_k, \\sum_1)$  -- $P(x|C_2) = N(u_k, \\sum_2)$\n",
    "\n",
    "#### Média da classe\n",
    "$u_k = 1/N_k * \\sum$\n",
    "\n",
    "\n",
    "$P (x | y = 0) = \\ dfrac {1} {(2 \\ pi) ^ {n / 2} * | \\ Sigma | ^ {1/2}} exp ({- 1/2 (x- \\ mu_0 ) ^ {T} \\ Sigma ^ {- 1} (x- \\ mu_0))} \\ hspace {1mm} - \\ hspace {1mm} \\ textbf {Eq \\ hspace {1mm} 1} \\\\ P (x | y = 1) = \\ dfrac {1} {(2 \\ pi) ^ {n / 2} * | \\ Sigma | ^ {1/2}} exp ({- 1/2 (x- \\ mu_1) ^ {T} \\ Sigma ^ {- 1} (x- \\ mu_1))} \\ hspace {1mm} - \\ hspace {1mm} \\ textbf {Eq \\ hspace {1mm} 2} \\\\ P (y) = \\ phi ^ y.  (1- \\ phi) ^ {1-y} \\ hspace {1mm} - \\ hspace {1mm} \\ textbf {Eq \\ hspace {1mm} \\ hspace {1mm} 3} \\\\       $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    m = y_train.shape[0] # Number of training example\n",
    "    #Reshapeing the training set\n",
    "    x_train = x_train.reshape(m, -1)\n",
    "    input_feature = x_train.shape[1] # Number of input feature. In our case it's 4\n",
    "    class_label = len(np.unique(y_train.reshape(-1))) # Number of class. In our case its 3.\n",
    "    \n",
    "    # Start everything with zero first.\n",
    "    # Mean for each class. Each row contains an individual class. And each of the class input is 4 dimenstional\n",
    "    mu = np.zeros((class_label, input_feature))\n",
    "    # Each row will conatain the covariance matrix of each class.\n",
    "    # The covariance matrix is a square symettric matrix.\n",
    "    # It indicates how each of the input feature varies with each other.\n",
    "    sigma = np.zeros((class_label, input_feature, input_feature))\n",
    "    # Prior probability of each class.\n",
    "    # Its the measure of knowing the likelihood of any class before seeing the input data.\n",
    "    phi = np.zeros(class_label)\n",
    "\n",
    "    for label in range(class_label):\n",
    "        # Seperate all the training data for a single class\n",
    "        indices = (y_train == label)\n",
    "        \n",
    "        phi[label] = float(np.sum(indices)) / m\n",
    "        mu[label] = np.mean(x_train[indices, :], axis=0)\n",
    "        # Instead of writting the equation we used numpy covariance function. \n",
    "        sigma[label] = np.cov(x_train[indices, :], rowvar=0)\n",
    "    \n",
    "    return phi, mu, sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MELHOR TUTORIAL\n",
    "https://towardsdatascience.com/logistic-regression-from-scratch-in-python-ec66603592e2\n",
    "\n",
    "https://github.com/arnaldog12/Machine_Learning/blob/master/Decision%20Trees.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
