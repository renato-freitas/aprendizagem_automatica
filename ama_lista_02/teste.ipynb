{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\"\"\"Program fits the training data to a gaussian model\n",
    "https://github.com/milaan9/Machine_Learning_Algorithms_from_Scratch/blob/master/02_PYTHON/02_Gaussian_Naive_Bayes/Gaussian_Naive_Bayes.ipynb\n",
    "\"\"\"\n",
    "escalar_minmax = MinMaxScaler()\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "\tdef __init__(self, train_file, test_file):\n",
    "\t\tself.classifier_dic = {}\n",
    "\t\tself.mean_dic = {}\n",
    "\t\tself.variance_dic = {}\n",
    "\t\tself.normal_dic = []\n",
    "\t\tself.unique_labels = []\n",
    "\t\tself.probability_dic = {}\n",
    "\t\tself.train_file = train_file\n",
    "\t\tself.test_file = test_file\n",
    "\n",
    "\tdef train(self):\n",
    "\t\t\"\"\" Trains the gaussian naive bayes classifier \"\"\"\n",
    "\n",
    "\t\ttrain_file_path = self.train_file\n",
    "\t\t# data_dic, self.unique_labels, total_number_of_rows, data_list = load_data_set(train_file_path)\n",
    "\n",
    "\t\tself.unique_labels = list(map(int, self.unique_labels))  #rótulos distintos em dicionário\n",
    "\t\tself.unique_labels = sorted(self.unique_labels) #rótulos distintos ordenados\n",
    "\t\tfor label in self.unique_labels:\n",
    "\t\t\tfor dimension in range(0, len(data_dic[label][0])):\n",
    "\t\t\t\tgaussian_training = GaussianTraining(data_dic[label], dimension)\n",
    "\t\t\t\tmean = gaussian_training.calculate_mean()\n",
    "\t\t\t\tvariance = gaussian_training.calculate_variacne()\n",
    "\t\t\t\tif variance < 0.0001:\n",
    "\t\t\t\t\tvariance = 0.0001\n",
    "\t\t\t\tif label in self.mean_dic:\n",
    "\t\t\t\t\tself.mean_dic[label].append(mean)\n",
    "\t\t\t\t\tself.variance_dic[label].append(variance)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.mean_dic[label] = [mean]\n",
    "\t\t\t\t\tself.variance_dic[label] = [variance]\n",
    "\t\t\t\tprint(\"Class %d, dimension %d, mean = %.2f, std = %.2f\" % (\n",
    "\t\t\t\tlabel, dimension + 1, mean, math.sqrt(variance)))\n",
    "\t\tself.probability_dic = GaussianTraining.probability_of_classifiers(self.unique_labels, total_number_of_rows, data_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m \u001b[39m# https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Gaussian%20Naive%20Bayes.ipynb\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\u001b[39m\"\u001b[39m\u001b[39m./breastcancer.csv\u001b[39m\u001b[39m\"\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, skip_header\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m dataset[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W5sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m escalar_minmax\u001b[39m.\u001b[39mfit_transform(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Gaussian%20Naive%20Bayes.ipynb\n",
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :-1]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:44\u001b[1;36m\u001b[0m\n\u001b[1;33m    test_file_path = self.test_file\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\tdef test(self):\n",
    "\t\t\t\t\"\"\" performs testing on test data \"\"\"\n",
    "\n",
    "\t\ttest_file_path = self.test_file\n",
    "\t\tnumber_of_test_rows, test_data = load_test_set(test_file_path)\n",
    "\t\tclassification = GaussianClassification(self.unique_labels, self.mean_dic, self.variance_dic, self.probability_dic)\n",
    "\t\tfor row in test_data:\n",
    "\t\t\tclassification.classify(row)\n",
    "\n",
    "\t\tclassification.display_accuracy(number_of_test_rows)\n",
    "\n",
    "\n",
    "class GaussianTraining:\n",
    "\tdef __init__(self, data, y):\n",
    "\t\tself.data_list = data\n",
    "\t\tself.column_number = y\n",
    "\t\tself.mean = 0\n",
    "\t\tself.sigma = 0\n",
    "\t\tself.variance = 0\n",
    "\n",
    "\tdef calculate_mean(self):\n",
    "\t\t\"\"\" Calculates mean of the given dimension\n",
    "\n",
    "        \tReturns\n",
    "        \t-------\n",
    "        \tself.mean : float\n",
    "                \t    mean over the given dimension\n",
    "       \t\t\"\"\"\n",
    "\n",
    "\t\tsummation = 0\n",
    "\t\tfor elements in self.data_list:\n",
    "\t\t\tsummation += elements[self.column_number]\n",
    "\t\tself.mean = summation / len(self.data_list)\n",
    "\t\treturn self.mean\n",
    "\tdef calculate_variacne(self):\n",
    "\t\t\"\"\" Calculates variance of the given dimension\n",
    "\n",
    "\t\tReturns\n",
    "\t\t----------------------------------------------------------------\n",
    "\t\tself.variance : float\n",
    "\t\t\t\tvariance over the given dimension\n",
    "        \t\"\"\"\n",
    "\t\t\n",
    "\t\tif len(self.data_list) == 0:\n",
    "\t\t\treturn 0\n",
    "\t\tsummation = 0\n",
    "\t\tfor elements in self.data_list:\n",
    "\t\t\tsummation += ((elements[self.column_number] - self.mean) * (elements[self.column_number] - self.mean))\n",
    "\t\tself.sigma = math.sqrt(summation / (len(self.data_list) - 1))\n",
    "\t\tself.variance = math.pow(self.sigma, 2)\n",
    "\t\treturn self.variance\n",
    "\n",
    "\tdef calculate_normal_distribution(self, label):\n",
    "\t\t\"\"\"Calculates normal distribution\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------------------------------------------------------\n",
    "\t\tlabel : int\n",
    "\t\t\tClass label.\n",
    "\t\n",
    "\t\tReturns\n",
    "\t\t----------------------------------------------------------\t\t\n",
    "\t\tnormal : float\n",
    "\t\t\t normal distribution over a dimension for a class label.\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tif self.variance == 0:\n",
    "\t\t\treturn 0\n",
    "\t\tdenominator = self.sigma * (math.sqrt(2 * math.pi))\n",
    "\t\tpower = ((-1) * math.pow((label - self.mean), 2)) / (2 * self.variance)\n",
    "\t\tnumerator = math.pow(math.e, power)\n",
    "\t\tnormal = numerator / denominator\n",
    "\t\treturn normal\n",
    "\t@staticmethod\n",
    "\tdef probability_of_classifiers(unique_labels, total_number_of_rows, data_dic):\n",
    "\t\t\"\"\"Calculates probability of class labels\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tunique_labels        :    list\n",
    "\t\t\t\t\t  contains list of unique class labels.\n",
    "\t\ttotal_number_of_rows :    int\n",
    "\t\t\t\t\t  number of samples in the training data\n",
    "\t\tdata_dic\t     :    dictionary\n",
    "\t\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tprobability_dic      : dictionary\n",
    "\t\t\t\t       class labels are key and their probabilities are dictionary\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tprobability_dic = {}\n",
    "\t\tfor labels in unique_labels:\n",
    "\t\t\tprobability = len(data_dic[labels]) / float(total_number_of_rows)\n",
    "\t\t\tprobability_dic[labels] = probability\n",
    "\t\treturn probability_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianClassification:\n",
    "\tdef __init__(self, unique_labels, mean, variance, probability_dic):\n",
    "\t\tself.unique_labels = unique_labels\n",
    "\t\tself.mean_dic = mean\n",
    "\t\tself.variance_dic = variance\n",
    "\t\tself.normal_dic = {}\n",
    "\t\tself.probability_dic = probability_dic\n",
    "\t\tself.correctly_classifed = 0\n",
    "\t\tself.total_probability = {}\n",
    "\n",
    "\tdef classify(self, data_row):\n",
    "\t\t\"\"\"classifies a new data\n",
    "\n",
    "\t\tParameters\n",
    "\t\t-----------------------------------------------------------------\n",
    "\t\tdata_row        :    list\n",
    "\t\t\t\t     contains unknown data to be classified\n",
    "\t\t\"\"\"\n",
    "\t\tself.normal_dic = {}\n",
    "\t\tfor label in self.unique_labels:\n",
    "\t\t\tfor column in range(0, len(data_row) - 2):\n",
    "\t\t\t\tnormal_result = self.calculate_normal_distribution(data_row[column], self.mean_dic[label][column], self.variance_dic[label][column])\n",
    "\t\t\t\tif label in self.normal_dic:\n",
    "\t\t\t\t\tself.normal_dic[label] *= normal_result\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.normal_dic[label] = normal_result\n",
    "\t\tmaximum = -1\n",
    "\t\tfor label in self.normal_dic:\n",
    "\t\t\tself.normal_dic[label] = (self.normal_dic[label] * self.probability_dic[label])\n",
    "\t\tdenominator = sum(self.normal_dic.values())\n",
    "\t\tfor label in self.normal_dic:\n",
    "\t\t\tself.normal_dic[label] /= (float(denominator))\n",
    "\t\t\tif maximum < self.normal_dic[label]:\n",
    "\t\t\t\tmaximum = self.normal_dic[label]\n",
    "\t\t\t\tclassified_as = label\n",
    "\n",
    "\t\taccuracy = 0\n",
    "\t\tif classified_as == data_row[-2]:\n",
    "\t\t\tself.correctly_classifed += 1\n",
    "\t\t\taccuracy = 1\n",
    "\t\tprint(\"ID = %5d, predicted = %3d, probability = %.4f, true=%3d, accuracy=%4.2f\" % (\n",
    "\t\tdata_row[-1], classified_as, maximum, data_row[-2], accuracy))\n",
    "\n",
    "\tdef display_accuracy(self, number_of_test_rows):\n",
    "\t\tprint(\"classification accuracy=%6.4lf \" % (self.correctly_classifed / float(number_of_test_rows)))\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef calculate_normal_distribution(value, mean, variance):\n",
    "\t\t\"\"\"Calculates normal distribution\n",
    "\n",
    "\t\t\t\tParameters\n",
    "\t\t\t\t-------------------------------------------------------\n",
    "\t\t\t\tvalue   :   float\n",
    "\t\t\t\t\t    value of x in f(x)\n",
    "\t\t\t\tmean    :   float\n",
    "\t\t\t\t\t    mean of the dimension\n",
    "\t\t\t\tvariance :  float\n",
    "\t\t\t\t            variance of the dimension\n",
    "\n",
    "\t\t\t\tReturns\n",
    "\t\t\t\t-------------------------------------------------------\n",
    "\t\t\t\tnormal : float\n",
    "\t\t\t\t\t normal distribution over a dimension.\n",
    "\t\t\"\"\"\n",
    "\t\tif variance < 0.0001:\n",
    "\t\t\tvariance = 0.0001\n",
    "\t\tdenominator = math.sqrt(variance * 2 * math.pi)\n",
    "\n",
    "\t\tpower = ((-1) * math.pow((value - mean), 2)) / float((2 * variance))\n",
    "\t\tnumerator = math.pow(math.e, power)\n",
    "\t\tnormal = numerator / float(denominator)\n",
    "\n",
    "\t\treturn normal\n",
    "def load_data_set(filename):\n",
    "\t\"\"\"Loads the training data from a file to the dictionary\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------------------------------------------------\n",
    "\t\tfilename   :   string\n",
    "\t\t\t       file path of training data\n",
    "\t\t\t\t\t\t\t       \n",
    "\t\tReturns\n",
    "\t\t----------------------------------------------------\n",
    "\t\tdictionary    : dictionary\n",
    "\t\t\t\tclass label as key : list of rows as value\n",
    "\t\tunique_labels : list\n",
    "\t\t \t\tlist of unique labels in the training data\n",
    "\t\tloop_count    : int\n",
    "\t\t\t\tnumber of training samples\n",
    "\t\tdata_list     : list\n",
    "\t\t\t\tlist of training data\n",
    "\t\"\"\"\n",
    "\tdata_list = []\n",
    "\tinput_file = open(filename, \"r\")\n",
    "\tprint(\"⤵\\n\")    \n",
    "\tunique_labels = []\n",
    "\tdictionary = {}\n",
    "\tloop_count = 0\n",
    "\tfor line in input_file:\n",
    "\t\trow_list = (line.split(\" \"))\n",
    "\t\trow_list = list(filter(None, row_list))\n",
    "\t\trow_list = list(map(float, row_list))\n",
    "\t\tdata_list.append(row_list)\n",
    "\t\tif row_list[-1] in dictionary:\n",
    "\t\t\tdictionary[row_list[-1]].append(row_list[0:-1])\n",
    "\t\telse:\n",
    "\t\t\tunique_labels.append(row_list[-1])\n",
    "\t\t\tdictionary[row_list[-1]] = [row_list[0:-1]]\n",
    "\t\tloop_count += 1\n",
    "\treturn dictionary, unique_labels, loop_count, data_list\n",
    "\n",
    "def load_test_set(filename):\n",
    "\t\"\"\"Loads the testing data from a file to the dictionary\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------------------------------------------------\n",
    "\t\tfilename   :   string\n",
    "\t\t\t       file path of training data\n",
    "\t\t\t\t\t\t\t       \n",
    "\t\tReturns\n",
    "\t\t----------------------------------------------------\n",
    "\t\tloop_count    : int\n",
    "\t\t\t\tnumber of training samples\n",
    "\t\tdata_list     : list\n",
    "\t\t\t\tlist of training data\n",
    "\t\"\"\"\n",
    "\tdata_list = []\n",
    "\tinput_file = open(filename, \"r\")\n",
    "\tloop_count = 0\n",
    "\tfor line in input_file:\n",
    "\t\trow_list = (line.split(\" \"))\n",
    "\t\trow_list = list(filter(None, row_list))\n",
    "\t\trow_list = list(map(float, row_list))\n",
    "\t\tdata_list.append(row_list + [loop_count])\n",
    "\t\tloop_count += 1\n",
    "\treturn loop_count, data_list\n",
    "\n",
    "\n",
    "def main():\n",
    "\t\n",
    "\tinput_line = input()\t    # Taking file path from user as input\n",
    "\tinput_list = input_line.split()  \t\t    # converting  the input to a list\n",
    "\n",
    "\tgaussian = Gaussian(input_list[1], input_list[2])   # making object of Gaussian\n",
    "\tgaussian.train()\n",
    "\tgaussian.test()\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "escalar_minmax = MinMaxScaler()\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :30]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtde de classes: 2\n",
      "soma2_k1: [0.01033967 0.02333426 0.00905147 0.00578138 0.04673026 0.01176362\n",
      " 0.01844979 0.00952237 0.04229854 0.03181892 0.01702083 0.01724363\n",
      " 0.01739694 0.02547224 0.01007429 0.01766135 0.02249299 0.01302986\n",
      " 0.01027509 0.01931289 0.00500574 0.03228488 0.00452806 0.01054912\n",
      " 0.04681536 0.00949032 0.01710703 0.01989457 0.00892501 0.00974144]\n"
     ]
    }
   ],
   "source": [
    "def obtem_prob_all_classes(x_treino, y_treino):\n",
    "    numero_de_features = x_treino.shape[1]\n",
    "    qtde_classes = len(np.unique(y_treino)) \n",
    "    print(f'qtde de classes: {qtde_classes}')\n",
    "    media_dk = np.zeros((qtde_classes, numero_de_features))\n",
    "    var_dk = np.zeros((qtde_classes, numero_de_features))\n",
    "    priori_binaria = [[.0, .0]]\n",
    "    \n",
    "    for classe_k in range(qtde_classes):\n",
    "      indices_da_classe_0 = (y_treino == 0)\n",
    "      indices_da_classe_1 = (y_treino == 1)\n",
    "    # print(f'y: {y_treino.shape[0]}')\n",
    "    # print(f'nk0: {sum(indices_da_classe_0)}')\n",
    "    # print(f'nk1: {sum(indices_da_classe_1)}')\n",
    "    nk0 = sum(indices_da_classe_0)\n",
    "    nk1 = sum(indices_da_classe_1)\n",
    "      \n",
    "    # p(x | C1) = N(u1, E1)\n",
    "    media_k0 = np.mean(x_treino[indices_da_classe_0, :])\n",
    "    media_k1 = np.mean(x_treino[indices_da_classe_1, :])\n",
    "\n",
    "    # soma_k1 = np.cov(x_treino[indices_da_classe_0, :])\n",
    "    # soma_k1_var = np.var(x_treino[indices_da_classe_0, :])\n",
    "    # soma2_k1_dot = ((x_treino[indices_da_classe_0, :] - media_k0) @ (x_treino[indices_da_classe_0, :] - media_k0).T) / (nk0 - 1)\n",
    "    soma2_k1 = sum((x_treino[indices_da_classe_0, :] - media_k0) * (x_treino[indices_da_classe_0, :] - media_k0)) / (nk0 - 1)\n",
    "\n",
    "    # print(f'soma_k1: {soma_k1}')\n",
    "    # print(f'soma_k1_var: {soma_k1_var}')\n",
    "    # print(f'soma2_k1_dot: {soma2_k1_dot}')\n",
    "    print(f'soma2_k1: {soma2_k1}')\n",
    "      # p(x | C2) = N(u2, E2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "obtem_prob_all_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "class GNB:\n",
    "  def __init__(self, prior=None, n_class=None, \n",
    "               mean=None, variance = None, classes=None):\n",
    "    # prior assumption of probability\n",
    "    self.prior = prior\n",
    "    # how many unique classes\n",
    "    self.n_class = n_class\n",
    "    # mean of x values\n",
    "    self.mean = mean\n",
    "    # variance of x values\n",
    "    self.variance = variance\n",
    "    # the unique classes present\n",
    "    self.classes = classes\n",
    "  # get the mean and variance of the x values\n",
    "  def fit(self, x, y):\n",
    "    # get the mean and variance of the x values\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.mean = np.array(x.groupby(by=y).mean())\n",
    "    self.variance = np.array(x.groupby(by=y).var())\n",
    "    self.n_class = len(np.unique(y))\n",
    "    self.classes = np.unique(y)\n",
    "    self.prior = 1/self.n_class\n",
    "    return self\n",
    "  def mean_var(self):\n",
    "    # mean and variance from the trainig data\n",
    "    m = np.array(self.mean)\n",
    "    v = np.array(self.variance)\n",
    "    # pull and combine the corresponding mean and variance\n",
    "    self.mean_var = []\n",
    "    for i in range(len(m)):\n",
    "      m_row = m[i]\n",
    "      v_row = v[i]\n",
    "      for a, b in enumerate(m_row):\n",
    "        mean = b\n",
    "        var = v_row[a]\n",
    "        self.mean_var.append([mean, var])\n",
    "    return self.mean_var\n",
    "  def split(self):\n",
    "    spt = np.vsplit(np.array(self.mean_var()), self.n_class)\n",
    "    print(f'vsplit: {spt}')\n",
    "    return spt\n",
    "  def gnb_base(self, x_val, x_mean, x_var):\n",
    "    # define the base formula for prediction probabilities\n",
    "    # Variance of the x value in question\n",
    "    self.x_val = x_val\n",
    "    # x mean value\n",
    "    self.x_mean = x_mean\n",
    "    # the x value that is being used for computation\n",
    "    self.x_var = x_var\n",
    "    # natural log\n",
    "    e = np.e\n",
    "    # pi\n",
    "    pi = np.pi\n",
    "    # first part of the equation\n",
    "    # 1 divided by the sqrt of 2 * pi * x_variance\n",
    "    equation_1 = 1/(np.sqrt(2 * pi * x_var))\n",
    "    \n",
    "    # second part of equation implementation\n",
    "    # denominator of equation\n",
    "    denom = 2 * x_var\n",
    "    # numerator calculation\n",
    "    numerator = (x_val - x_mean) ** 2\n",
    "    # the exponent\n",
    "    expo = np.exp(-(numerator/denom))\n",
    "    prob = equation_1 * expo\n",
    "    return prob\n",
    "  def predict(self, X):\n",
    "    self.X = X\n",
    "    # calculate the probabilities using base formula above\n",
    "    # defining the mean and variance that has being split into\n",
    "    # various classes.\n",
    "    split_class = self.split()\n",
    "    prob = []\n",
    "    for i in range(self.n_class):\n",
    "      # first class\n",
    "      class_one = split_class[i]\n",
    "      for i in range(len(class_one)):\n",
    "        # first value in class one\n",
    "        class_one_x_mean = class_one[i][0]\n",
    "        class_one_x_var = class_one[i][1]\n",
    "        x_value = X[i]\n",
    "        # now calculate the probabilities of each class. \n",
    "        prob.append([self.gnb_base(x_value, class_one_x_mean, \n",
    "                                   class_one_x_var)])\n",
    "      # turn prob into an array\n",
    "      prob_array = np.array(prob)\n",
    "      # split the probability into various classes again\n",
    "      prob_split = np.vsplit(prob_array, self.n_class)\n",
    "      # calculate the final probabilities\n",
    "      final_probabilities = []\n",
    "      for i in prob_split:\n",
    "        class_prob = np.prod(i) * self.prior\n",
    "        final_probabilities.append(class_prob)\n",
    "      # determining the maximum probability \n",
    "      maximum_prob = max(final_probabilities)\n",
    "      # getting the index that corresponds to maximum probability\n",
    "      prob_index = final_probabilities.index(maximum_prob)\n",
    "      # using the index of the maximum probability to get\n",
    "      # the class that corresponds to the maximum probability\n",
    "      prediction = self.classes[prob_index]\n",
    "      return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsplit: [array([[2.42473374e-01, 6.99880845e-03],\n",
      "       [2.68125287e-01, 1.63610944e-02],\n",
      "       [2.35108076e-01, 6.50934048e-03],\n",
      "       [1.34060362e-01, 3.19683513e-03],\n",
      "       [3.59574266e-01, 1.60545574e-02],\n",
      "       [1.87537307e-01, 1.17560598e-02],\n",
      "       [1.12012575e-01, 1.31306984e-02],\n",
      "       [1.28840917e-01, 6.37867013e-03],\n",
      "       [3.46146108e-01, 1.61553032e-02],\n",
      "       [2.79217806e-01, 2.28657706e-02],\n",
      "       [6.18857543e-02, 1.85164643e-03],\n",
      "       [1.86078603e-01, 1.72419722e-02],\n",
      "       [5.85843316e-02, 1.40188555e-03],\n",
      "       [2.65267507e-02, 3.19595934e-04],\n",
      "       [1.82168777e-01, 1.00673761e-02],\n",
      "       [1.47627069e-01, 1.62742715e-02],\n",
      "       [6.95407383e-02, 9.15450674e-03],\n",
      "       [1.92104157e-01, 1.29761838e-02],\n",
      "       [1.79764597e-01, 1.02496994e-02],\n",
      "       [9.94166800e-02, 1.19933690e-02],\n",
      "       [1.91416649e-01, 4.96168815e-03],\n",
      "       [2.94467570e-01, 2.02062975e-02],\n",
      "       [1.80516627e-01, 4.50969158e-03],\n",
      "       [9.04590422e-02, 1.61310164e-03],\n",
      "       [3.52258675e-01, 1.86538230e-02],\n",
      "       [1.52616146e-01, 8.45063926e-03],\n",
      "       [1.36391390e-01, 1.47545313e-02],\n",
      "       [2.58584677e-01, 1.44267009e-02],\n",
      "       [2.25638459e-01, 7.24972044e-03],\n",
      "       [1.64653759e-01, 9.33415243e-03]]), array([[0.49869779, 0.02050976],\n",
      "       [0.40601864, 0.0144672 ],\n",
      "       [0.49677276, 0.02039752],\n",
      "       [0.35429435, 0.0205524 ],\n",
      "       [0.45044856, 0.0129614 ],\n",
      "       [0.38398425, 0.02550466],\n",
      "       [0.37837765, 0.03108782],\n",
      "       [0.4372978 , 0.03128052],\n",
      "       [0.43936124, 0.01925329],\n",
      "       [0.25676998, 0.02128721],\n",
      "       [0.16773336, 0.00935392],\n",
      "       [0.18092171, 0.00863239],\n",
      "       [0.15490863, 0.00781265],\n",
      "       [0.11225901, 0.00566868],\n",
      "       [0.17430801, 0.01142406],\n",
      "       [0.22588954, 0.021218  ],\n",
      "       [0.10663796, 0.00312133],\n",
      "       [0.279592  , 0.00957554],\n",
      "       [0.16917236, 0.01350698],\n",
      "       [0.10718538, 0.00496732],\n",
      "       [0.46825037, 0.0213398 ],\n",
      "       [0.46608236, 0.02087159],\n",
      "       [0.45208549, 0.01970723],\n",
      "       [0.30120277, 0.01883474],\n",
      "       [0.49208386, 0.02200638],\n",
      "       [0.33899424, 0.02929601],\n",
      "       [0.36680867, 0.02126309],\n",
      "       [0.62557195, 0.02824089],\n",
      "       [0.32884916, 0.01845059],\n",
      "       [0.23540837, 0.01985793]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :30]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "gnb = GNB()\n",
    "\n",
    "X = pd.DataFrame(data=X_train)\n",
    "y = pd.Series(y_train)\n",
    "# fit the class to the x_values and target\n",
    "gnb.fit(X, y)\n",
    "# given these X values, let's do a prediction\n",
    "gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
