{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista 2 - Regressão Logística e métodos estatísticos\n",
    "Aprendizagem de Máquina - 2023.1\n",
    "\n",
    "José Renato S. Freitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import multivariate_normal\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalar_minmax = MinMaxScaler()\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funções\n",
    "def sigmoide(z):\n",
    "  \"\"\"Função logística Sigmóide, y^i = o(wTxi), o(z) = 1/1 + exp(-z)\"\"\"\n",
    "  return 1/(1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def custo_cross_entropia_binaria(y, y_pred):\n",
    "  \"\"\"Função Custo Cross Entropy, Regressão Logística Binária\"\"\"\n",
    "  sujeira = 1.0e-18 \n",
    "  return -np.mean(y*(np.log(sujeira + y_pred)) + (1 - y)*np.log(sujeira + (1 - y_pred)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :30]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1\n",
      "Fold 1 [0.08070175438596491, 0.4868223482635652, 0.054385964912280704, 0.02631578947368421]\n",
      "Fold 2 [0.16666666666666666, 0.4962152850431912, 0.10175438596491229, 0.0649122807017544]\n",
      "Fold 3 [0.2631578947368421, 0.4772445792538752, 0.1631578947368421, 0.1]\n",
      "Fold 4 [0.3614035087719298, 0.4906011036529671, 0.22280701754385968, 0.13859649122807016]\n",
      "Fold 5 [0.4508771929824561, 0.4714045207910317, 0.28771929824561404, 0.16315789473684209]\n",
      "Fold 6 [0.5385964912280701, 0.4868223482635652, 0.3456140350877193, 0.19298245614035087]\n",
      "Fold 7 [0.631578947368421, 0.4772445792538752, 0.4087719298245614, 0.22280701754385962]\n",
      "Fold 8 [0.7157894736842104, 0.4714045207910317, 0.4631578947368421, 0.25263157894736843]\n",
      "Fold 9 [0.8068609022556391, 0.4883855118277623, 0.518515037593985, 0.2883458646616541]\n",
      "Fold 10 [0.8943609022556391, 0.49196347549842545, 0.5720864661654136, 0.32227443609022555]\n"
     ]
    }
   ],
   "source": [
    "epocas = 1000\n",
    "alfa = .3\n",
    "custos = []\n",
    "\n",
    "def regressao_logistica(X, y, W):\n",
    "  n = X.shape[0]\n",
    "  for i in range(epocas):\n",
    "      z = X @ W\n",
    "      y_pred = sigmoide(z)\n",
    "      erro = y - y_pred\n",
    "      \n",
    "      W = W + alfa*((X.T @ erro)/n)\n",
    "      custo = custo_cross_entropia_binaria(y, y_pred)\n",
    "      custos.append([i, custo])\n",
    "  return W\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "fold = 0\n",
    "classe_k = []\n",
    "acuracia = 0.0\n",
    "acuracia_classe1 = 0.0\n",
    "acuracia_classe2 = 0.0\n",
    "print(f'       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1')\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  fold += 1\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "  _W = np.zeros(X_train.shape[1])\n",
    "\n",
    "  # Treino\n",
    "  result_W = regressao_logistica(X_train, y_train, _W)\n",
    "  \n",
    "  # Teste\n",
    "  z_teste = X_test @ result_W\n",
    "  y_predito = sigmoide(z_teste)\n",
    "  \n",
    "\n",
    "  # obter a acurrácia\n",
    "  classes_preditas = [1 if i > 0.5 else 0 for i in y_predito]\n",
    "  classe1 = [i if i == 0 else None for i in classes_preditas]\n",
    "  classe2 = [i if i == 1 else None for i in classes_preditas]\n",
    "  acuracia += np.sum(y_test == classes_preditas)*1.00/len(y_test)\n",
    "  acuracia_classe1 += np.sum(y_test == classe1)*1.00/len(y_test)\n",
    "  acuracia_classe2 += np.sum(y_test == classe2)*1.00/len(y_test)\n",
    "  \n",
    "  print(f'Fold {fold} [{acuracia/10}, {np.std(classes_preditas, dtype=np.float64)}, {acuracia_classe1/10}, {acuracia_classe2/10}]')\n",
    "\n",
    "# df_historico_k_custo = pd.DataFrame(data=custos, columns=['t','c'])\n",
    "# fig, (ax1) = plt.subplots(1, 1)\n",
    "# fig.suptitle(\"Fold \" + str(fold))\n",
    "# fig.set_figwidth(10)\n",
    "# fig.set_figheight(6)\n",
    "# ax1.plot(df_historico_k_custo['t'], df_historico_k_custo['c'], color='red')\n",
    "# ax1.plot(df_historico_k_custo['t'], df_historico_k_custo['c'])\n",
    "# df_historico_k_custo = pd.DataFrame(data=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise do Discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :30]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treina_analise_discriminante_gaussiano(x_treino, y_treino):\n",
    "    n = y_treino.shape[0]\n",
    "    numero_de_features = x_treino.shape[1]\n",
    "\n",
    "    rotulo_das_classes_no_dataset = len(np.unique(y_treino))\n",
    "    mu = np.zeros((rotulo_das_classes_no_dataset, numero_de_features))\n",
    "    prob_classe = np.zeros(rotulo_das_classes_no_dataset)\n",
    "    sigma = np.zeros((rotulo_das_classes_no_dataset, numero_de_features, numero_de_features))\n",
    "\n",
    "    for classe in range(rotulo_das_classes_no_dataset):\n",
    "        indices_da_classe_k = (y_train == classe)\n",
    "        nk = float(np.sum(indices_da_classe_k))\n",
    "\n",
    "        prob_classe[classe] = nk / n\n",
    "\n",
    "        mu[classe] = np.mean(x_treino[indices_da_classe_k, :], axis=0)\n",
    "       \n",
    "        sigma[classe] = np.cov(x_treino[indices_da_classe_k, :], rowvar=0)\n",
    "\n",
    "    return prob_classe, mu, sigma\n",
    "\n",
    "\n",
    "def testa_analise_discriminante_gaussiano(x_tests, probs, mu, sigma):\n",
    "    x_tests = x_tests.reshape(x_tests.shape[0], -1)\n",
    "    rotulo_das_classes = mu.shape[0] \n",
    "    ws = np.zeros((x_tests.shape[0], rotulo_das_classes))  \n",
    "    \n",
    "    for rotulo in range(rotulo_das_classes): \n",
    "        normal_distribution_prob = multivariate_normal(mean=mu[rotulo], cov=sigma[rotulo])\n",
    "        for i, x_test in enumerate(x_tests):\n",
    "            ws[i, rotulo] = np.log(probs[rotulo]) + normal_distribution_prob.logpdf(x_test)\n",
    "    predictions = np.argmax(ws, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1\n",
      "Fold 1 [0.09122807017543859, 0.4772445792538752, 0.06140350877192983, 0.02982456140350877]\n",
      "Fold 2 [0.1894736842105263, 0.4980726163711716, 0.11403508771929824, 0.07543859649122805]\n",
      "Fold 3 [0.28771929824561404, 0.4906011036529671, 0.1736842105263158, 0.11403508771929824]\n",
      "Fold 4 [0.38596491228070173, 0.4906011036529671, 0.23333333333333334, 0.1526315789473684]\n",
      "Fold 5 [0.4842105263157895, 0.4493420517496736, 0.30526315789473685, 0.1789473684210526]\n",
      "Fold 6 [0.5789473684210527, 0.464829519280413, 0.37017543859649127, 0.2087719298245614]\n",
      "Fold 7 [0.6771929824561405, 0.4714045207910317, 0.436842105263158, 0.24035087719298245]\n",
      "Fold 8 [0.7666666666666667, 0.4868223482635652, 0.4912280701754387, 0.2754385964912281]\n",
      "Fold 9 [0.8613095238095239, 0.49487165930539345, 0.5465852130325816, 0.31472431077694235]\n",
      "Fold 10 [0.955952380952381, 0.4841229182759271, 0.605513784461153, 0.3504385964912281]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "fold = 0\n",
    "classe_k = []\n",
    "acuracia_adg = 0.0\n",
    "acuracia_classe1_adg = 0.0\n",
    "acuracia_classe2_adg = 0.0\n",
    "\n",
    "print(f'       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1')\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  fold += 1\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "  _W = np.zeros(X_train.shape[1])\n",
    "\n",
    "  prob_classe, mu, sigma = treina_analise_discriminante_gaussiano(X_train, y_train)\n",
    "\n",
    "  y_predito = testa_analise_discriminante_gaussiano(X_test, prob_classe, mu, sigma)\n",
    "  classe1 = [i if i == 0 else None for i in y_predito]\n",
    "  classe2 = [i if i == 1 else None for i in y_predito]\n",
    "\n",
    "  acuracia_adg += np.sum(y_test == y_predito)*1.00/len(y_test)\n",
    "  acuracia_classe1_adg += np.sum(y_test == classe1)*1.00/len(y_test)\n",
    "  acuracia_classe2_adg += np.sum(y_test == classe2)*1.00/len(y_test)\n",
    "  \n",
    "  print(f'Fold {fold} [{acuracia_adg/K}, {np.std(y_predito, dtype=np.float64)}, {acuracia_classe1_adg/10}, {acuracia_classe2_adg/10}]')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt(\"./breastcancer.csv\", delimiter=',', skip_header=1)\n",
    "x = dataset[:, :30]\n",
    "X = escalar_minmax.fit_transform(x)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treina_naive_bayes_gaussiano2(x_treino, y_treino):\n",
    "    \n",
    "    numero_de_features = x_treino.shape[1]\n",
    "    qtde_rotulos_classes = len(np.unique(y_treino)) # qtd de rótulos distintos\n",
    "    media_dk = np.zeros((qtde_rotulos_classes, numero_de_features))\n",
    "    var_dk = np.zeros((qtde_rotulos_classes, numero_de_features))\n",
    "\n",
    "    for classe_k in range(qtde_rotulos_classes):\n",
    "        indices_da_classe_k = (y_train == classe_k)\n",
    "        nk = sum(indices_da_classe_k)\n",
    "\n",
    "        # Para cada dimensão d em X\n",
    "        for d in range(numero_de_features):\n",
    "            # obter a média de cada dimensão (feature) por classe\n",
    "            media_dk[classe_k][d] = np.mean(x_treino[indices_da_classe_k, d])\n",
    "            # obter a variancia de cada dimensão por classe\n",
    "            var_dk[classe_k][d] = sum((x_treino[indices_da_classe_k, d] - media_dk[classe_k][d]) * (x_treino[indices_da_classe_k, d] - media_dk[classe_k][d])) / (nk - 1)\n",
    "    return media_dk, var_dk\n",
    "\n",
    "# def teste_naive_bayes_gaussiano_(x_test, y_test, media, var):\n",
    "#     numero_de_features = x_test.shape[1]\n",
    "#     qtde_rotulos_classes = len(np.unique(y_test)) \n",
    "\n",
    "#     y_predito = np.zeros(y_test.shape[0], 1)\n",
    "    \n",
    "#     for classe_k in range(qtde_rotulos_classes):\n",
    "#         parte1 = 0.0\n",
    "#         parte2 = 0.0\n",
    "#         for d in range(numero_de_features):\n",
    "#             # print(f'var_dk[{classe_k},{d}]: {var[classe_k][d]}')\n",
    "#             log1 = np.log( 2 * np.pi * var[classe_k][d])\n",
    "#             # print(f'log1: {log1}')\n",
    "#             parte1 += log1\n",
    "        \n",
    "#             fg2 = math.pow(np.sum(x_test[:, d] - media[classe_k][d]), 2)\n",
    "#             # print(f'fg2: {np.sum(fg2)}')\n",
    "\n",
    "#             parte2 += (fg2)/var[classe_k][d]\n",
    "#             # for xi in x_test[:, d]:\n",
    "#             #     xi_menos_media = xi - media[classe_k][d]\n",
    "#             #     parte2 += ((xi_menos_media)*(xi_menos_media)) / (var[classe_k][d])\n",
    "#         print(f'probab: {np.log(1/qtde_rotulos_classes) - (parte1/2) - (parte2/2)}')\n",
    "#         y_predito = np.log(0.5) - (parte1/2) - (parte2/2)\n",
    "#     return y_predito\n",
    "\n",
    "\n",
    "def probabilidade_x_dado_classe(x_test, media, var):\n",
    "    part_1_da_equacao = 1/(np.sqrt(2 * np.pi * var))\n",
    "    numerator = math.pow(x_test - media, 2)\n",
    "    probabilidade = part_1_da_equacao * np.exp(-(numerator/(2*var)))\n",
    "    return probabilidade\n",
    "\n",
    "def teste_naive_bayes_gaussiano(x_test, y_test, media, var):\n",
    "    numero_de_features = x_test.shape[1]\n",
    "    qtde_rotulos_classes = len(np.unique(y_test)) \n",
    "    \n",
    "    #priori binária\n",
    "    prob_c0, prob_c1 = 1/qtde_rotulos_classes, 1/qtde_rotulos_classes\n",
    "\n",
    "    # encontrar a evidencia\n",
    "    # prob_c0 * prob_x0|c0 * prob_xn | c0 +\n",
    "    # prob_c1 * prob_x0|c1 * prob_xn | c1  \n",
    "    probs = dict()\n",
    "    y_predito = []\n",
    "    for i in range(x_test.shape[0]): # para essa entrada, qual a classe predita\n",
    "        # calcular a probabilidade de xi dado a Classe k -> p(x | Ck)\n",
    "        for classe_k in range(qtde_rotulos_classes):\n",
    "            prob_x_ck = []\n",
    "            for d in range(numero_de_features):\n",
    "                prob_x_ck.append(probabilidade_x_dado_classe(x_test[i, d], media[classe_k][d], var[classe_k][d]))\n",
    "                probs[classe_k] = prob_x_ck\n",
    "\n",
    "        verossi = []\n",
    "        for i in probs:\n",
    "            verossi.append(np.prod(probs[i]) * prob_c0)\n",
    "        maior_prob = max(verossi)\n",
    "        y_predito.append(verossi.index(maior_prob))\n",
    "    return y_predito\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1\n",
      "Fold 1 [0.08947368421052632, 0.4574878880843964, 0.02631578947368421, 0.0]\n",
      "Fold 2 [0.18596491228070175, 0.4962152850431912, 0.07017543859649122, 0.0]\n",
      "Fold 3 [0.28421052631578947, 0.4906011036529671, 0.10877192982456138, 0.0]\n",
      "Fold 4 [0.38421052631578945, 0.4868223482635652, 0.14736842105263154, 0.0]\n",
      "Fold 5 [0.4807017543859649, 0.4574878880843964, 0.17368421052631575, 0.0]\n",
      "Fold 6 [0.5684210526315789, 0.464829519280413, 0.19999999999999996, 0.0]\n",
      "Fold 7 [0.6578947368421052, 0.4868223482635652, 0.22982456140350874, 0.0]\n",
      "Fold 8 [0.7491228070175439, 0.4714045207910317, 0.2631578947368421, 0.0]\n",
      "Fold 9 [0.8419799498746867, 0.4841229182759271, 0.2988721804511278, 0.023214285714285715]\n",
      "Fold 10 [0.9348370927318296, 0.48838551182776224, 0.33458646616541354, 0.05892857142857143]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "kfold = KFold(n_splits=K, random_state=42, shuffle=True)\n",
    "fold = 0\n",
    "classe = []\n",
    "acuracia_nbg = 0.0\n",
    "acuracia_classe1_nbg = 0.0\n",
    "acuracia_classe2_nbg = 0.0\n",
    "\n",
    "print(f'\\tValor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1')\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  fold += 1\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "  # modelo_nbg = clf.fit(X_train, y_train)\n",
    "  # predito = modelo_nbg.predict(X_test[:10, :30])\n",
    "  # print(f'\\tPredição GaussianNG do Sklearn: {predito}')\n",
    "\n",
    "  media, var = treina_naive_bayes_gaussiano2(X_train, y_train)\n",
    "  \n",
    "  y_predito = teste_naive_bayes_gaussiano(X_test, y_test, media, var)\n",
    "\n",
    "  classe0 = [i if i == 0 else None for i in y_predito]\n",
    "  classe1 = [i if i == 1 else None for i in y_predito]\n",
    "  # print(f'\\ty_predito:                      {(y_predito[:10])}')\n",
    "\n",
    "  acuracia_nbg += np.sum(y_test == y_predito)*1.00/len(y_test)\n",
    "  acuracia_classe1_nbg += np.sum(y_test == classe1)*1.00/len(y_test)\n",
    "  acuracia_classe2_nbg += np.sum(y_test == classe2)*1.00/len(y_test)\n",
    "  \n",
    "  print(f'Fold {fold} [{acuracia_nbg/K}, {np.std(y_predito, dtype=np.float64)}, {acuracia_classe1_nbg/K}, {acuracia_classe2_nbg/K}]')\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt(\"./vehicle.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :19]\n",
    "X = escalar_minmax.fit_transform(X)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "alfa2 = 0.1\n",
    "epocas2 = 1000\n",
    "custos2 = []\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "def my_softmax2(z):\n",
    "  exp = np.exp(z)\n",
    "  return (exp / np.sum(exp))\n",
    "\n",
    "def custo_multi_cross_entropia(y, y_predi):\n",
    "    \"\"\"cross_entropy_loss\"\"\"\n",
    "    return -np.mean(np.sum(y * np.log(y_predi)))\n",
    "\n",
    "def acuracia(y, y_hat):\n",
    "    return np.sum(y == y_hat)/len(y)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "def treina(X, y):\n",
    "  _x = np.c_[np.ones(X.shape[0]), X]\n",
    "  y_encode = one_hot_encoder.fit_transform(y.reshape(-1,1))\n",
    "  W = np.zeros((_x.shape[1], y_encode.shape[1]))\n",
    "  \n",
    "  y_predi = None\n",
    "  n = X.shape[0]\n",
    "  for i in range(epocas2):\n",
    "    z = _x @ W\n",
    "    y_predi = softmax(z)\n",
    "    erro = y_encode - y_predi\n",
    "    \n",
    "    W = W + alfa2*((_x.T @ erro)/n)\n",
    "    custo2 = custo_multi_cross_entropia(y_encode, y_predi)\n",
    "    custos2.append([i, custo2])\n",
    "  return W\n",
    "   \n",
    "\n",
    "def testa(X, W):\n",
    "  features = np.c_[np.ones(X.shape[0]), X]\n",
    "  z = features @ W\n",
    "  y_predi_ = softmax(z)\n",
    "  return y_predi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1, Acurácia classe 2, Acurácia classe 3\n",
      "Fold 10 [0.08823529411764705, 1.1642898841165181, 0.024705882352941178, 0.02235294117647059, 0.02235294117647059, 0.018823529411764704]\n",
      "Fold 10 [0.1764705882352941, 1.2621725653709506, 0.049411764705882356, 0.03764705882352941, 0.03882352941176471, 0.05058823529411764]\n",
      "Fold 10 [0.2752941176470588, 1.048313854585669, 0.07529411764705882, 0.06823529411764706, 0.06470588235294118, 0.06705882352941175]\n",
      "Fold 10 [0.36705882352941177, 1.1942190626305431, 0.09529411764705882, 0.09058823529411765, 0.0811764705882353, 0.1]\n",
      "Fold 10 [0.46352941176470586, 1.1697454843981643, 0.13058823529411764, 0.11058823529411765, 0.10235294117647058, 0.12]\n",
      "Fold 10 [0.5551960784313725, 1.239182215155736, 0.16511204481792716, 0.13082633053221288, 0.11544817927170867, 0.1438095238095238]\n",
      "Fold 10 [0.6468627450980392, 1.1639911011028874, 0.18773109243697478, 0.14630252100840338, 0.14401960784313722, 0.1688095238095238]\n",
      "Fold 10 [0.7373389355742297, 1.1050287034164088, 0.20558823529411763, 0.17725490196078433, 0.16425770308123247, 0.19023809523809523]\n",
      "Fold 10 [0.8278151260504203, 1.1842695348043701, 0.23535014005602237, 0.20106442577030811, 0.18211484593837532, 0.20928571428571424]\n",
      "Fold 10 [0.9218627450980392, 1.1368891796488878, 0.25796918767507, 0.22487394957983192, 0.20592436974789913, 0.23309523809523808]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=K, random_state=42, shuffle=True)\n",
    "acuracia_ = 0.0\n",
    "acuracia_classe_zero,  acuracia_classe_um, acuracia_classe_dois, acuracia_classe_tres= 0.0, 0.0, 0.0, 0.0\n",
    "print(f'       Valor Médio Aurácia,      Desvio Padrão,      Acurácia classe 0,     Acurácia classe 1, Acurácia classe 2, Acurácia classe 3')\n",
    "for train_index, test_index in kfold.split(X):\n",
    "\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "  \n",
    "  ws = treina(X_train, y_train)\n",
    "  \n",
    "  y_ch = testa(X_test, ws)\n",
    "  classes_preditas = np.array([np.argmax(y)*1.0 for y in y_ch])\n",
    "\n",
    "  # obter a acurrácia\n",
    "  classe_zero= [i if i == 0 else None for i in classes_preditas]\n",
    "  classe_um = [i if i == 1 else None for i in classes_preditas]\n",
    "  classe_dois = [i if i == 2 else None for i in classes_preditas]\n",
    "  classe_tres = [i if i == 3 else None for i in classes_preditas]\n",
    "  acuracia_ += np.sum(y_test == classes_preditas)*1.00/len(y_test)\n",
    "  acuracia_classe_zero += np.sum(y_test == classe_zero)*1.00/len(y_test)\n",
    "  acuracia_classe_um += np.sum(y_test == classe_um)*1.00/len(y_test)\n",
    "  acuracia_classe_dois += np.sum(y_test == classe_dois)*1.00/len(y_test)\n",
    "  acuracia_classe_tres += np.sum(y_test == classe_tres)*1.00/len(y_test)\n",
    "\n",
    "  print(f'Fold {fold} [{acuracia_/K}, {np.std(classes_preditas, dtype=np.float64)}, {acuracia_classe_zero/K}, {acuracia_classe_um/K}, {acuracia_classe_dois/K}, {acuracia_classe_tres/K}]')\n",
    "\n",
    "# df_historico_multi_custo = pd.DataFrame(data=custos2, columns=['t','c'])\n",
    "# fig, (ax1) = plt.subplots(1, 1)\n",
    "# fig.suptitle(\"Custo Cross Entroty\")\n",
    "# fig.set_figwidth(12)\n",
    "# ax1.plot(df_historico_multi_custo['t'], df_historico_multi_custo['c'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
